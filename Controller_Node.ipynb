{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\lib\\python\\namedtuple.py:237: UserWarning: torch.eig is deprecated in favor of torch.linalg.eig and will be removed in a future PyTorch release.\n",
      "torch.linalg.eig returns complex tensors of dtype cfloat or cdouble rather than real tensors mimicking complex tensors.\n",
      "L, _ = torch.eig(A)\n",
      "should be replaced with\n",
      "L_complex = torch.linalg.eigvals(A)\n",
      "and\n",
      "L, V = torch.eig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L_complex, V_complex = torch.linalg.eig(A) (Triggered internally at  ..\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:2897.)\n",
      "  eig = x.eig(True)\n",
      "c:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\lib\\python\\namedtuple.py:243: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
      "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
      "To get the qr decomposition consider using torch.linalg.qr.\n",
      "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
      "The unpacking of the solution, as in\n",
      "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
      "should be replaced with\n",
      "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  ..\\aten\\src\\ATen\\LegacyTHFunctionsCPU.cpp:389.)\n",
      "  lstsq = A.lstsq(B)\n",
      "c:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\lib\\python\\namedtuple.py:249: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at  ..\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:1940.)\n",
      "  qr = x.qr()\n",
      "c:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\lib\\python\\namedtuple.py:255: UserWarning: torch.solve is deprecated in favor of torch.linalg.solveand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve has its arguments reversed and does not return the LU factorization.\n",
      "To get the LU factorization see torch.lu, which can be used with torch.lu_solve or torch.lu_unpack.\n",
      "X = torch.solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve(A, B) (Triggered internally at  ..\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:760.)\n",
      "  solve = s.solve(s)\n",
      "c:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\lib\\python\\namedtuple.py:261: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  ..\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:2500.)\n",
      "  symeig = s.symeig()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Tensor' has no attribute 'fft'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cf794ee3a41b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msyft\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_serialize\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mserialize\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepr_service\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReprMessage\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDevice\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeviceClient\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msyft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDomain\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\core\\node\\device\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# syft relative\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeviceClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"DeviceClient\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\core\\node\\device\\client.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSpecificLocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRoute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\core\\node\\common\\client.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpointer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpointer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPointer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msyft_decorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlib_ast\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClient\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mClient_PB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetadata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mMetadata_PB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\lib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# constructor: copyType = create_lib_ast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mlib_ast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_lib_ast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mlib_ast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_lib_ast\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\lib\\__init__.py\u001b[0m in \u001b[0;36mcreate_lib_ast\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mpython_ast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_python_ast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtorch_ast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_torch_ast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtorchvision_ast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_torchvision_ast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# numpy_ast = create_numpy_ast()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\lib\\torch\\__init__.py\u001b[0m in \u001b[0;36mcreate_torch_ast\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             ast.add_path(\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework_reference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m             )\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m# add all the torch.nn.Parameter hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\ast\\globals.py\u001b[0m in \u001b[0;36madd_path\u001b[1;34m(self, path, index, return_type_name, framework_reference)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"add_path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             attr.add_path(  # type: ignore\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             )\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\ast\\module.py\u001b[0m in \u001b[0;36madd_path\u001b[1;34m(self, path, index, return_type_name, framework_reference)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"add_path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             attr.add_path(  # type: ignore\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_type_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\roaming\\python\\python36\\site-packages\\syft\\ast\\callable.py\u001b[0m in \u001b[0;36madd_path\u001b[1;34m(self, path, index, return_type_name)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                 \u001b[0mattr_ref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr_ref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Tensor' has no attribute 'fft'"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm \n",
    "from time_tracker import time_tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = time_tracker(interval = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets the name of the saved data, based on device and resource state, and the number of models to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = 'Stationary_WIFI'\n",
    "rpi_name = 'RPi8_1500'\n",
    "num_of_models = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Openmined's course: \n",
    "https://courses.openmined.org/courses/foundations-of-private-computation\n",
    "\n",
    "The code for the Controller used in course can be found here: \n",
    "https://github.com/OpenMined/courses/blob/foundations-of-private-computation/federated-learning/duet_mnist/MNIST_Syft_Data_Scientist.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duet_RPi8_1500 = sy.join_duet(target_id=\"438be5a282e90f571b435feae2d0b648\", network_url=\"http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\")\n",
    "duet = sy.join_duet(target_id=\"2bd79a82ed05fb869cf1482c9f24455d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = duet.torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression Model Dimensions (each image is 8x8, with 10 labeles, and 1437 samples)\n",
    "in_dim = 64\n",
    "out_dim = 10\n",
    "n_samples = 1437\n",
    "\n",
    "#LR Model traning Parameters\n",
    "learning_rate = 0.01\n",
    "\n",
    "iteration = 100\n",
    "\n",
    "#Arrays required to compute RCoin Values\n",
    "\n",
    "RCoins = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref = torch_ref)\n",
    "        self.layer1 = self.torch_ref.nn.Linear(in_dim, 128)\n",
    "        self.layer2 = self.torch_ref.nn.Linear(128, 256)\n",
    "        self.layer3 = self.torch_ref.nn.Linear(256, 50)\n",
    "        self.dropout1 = self.torch_ref.nn.Dropout(0.25)\n",
    "        self.out = self.torch_ref.nn.Linear(50, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #with profiler_ref.record_function(\"Forward Pass\"):\n",
    "        x = self.torch_ref.nn.functional.relu(self.layer1(x))\n",
    "        x = self.torch_ref.nn.functional.relu(self.layer2(x))\n",
    "        x = self.torch_ref.nn.functional.relu(self.layer3(x))\n",
    "        output = self.torch_ref.nn.functional.log_softmax(self.out(x), dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr, monitor): #profiler_ref\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        iter_start_time = time.time()\n",
    "        optim.zero_grad()\n",
    "        #with profiler_ref.profile(profiler_memory=True) as prof:\n",
    "        output = model(data_ptr)\n",
    "\n",
    "        # nll_loss = negative log-liklihood loss\n",
    "        loss = torch_ref.nn.functional.nll_loss(output, target_ptr.long())\n",
    "\n",
    "        loss_item = loss.item()\n",
    "        \n",
    "        loss_value = loss_item.get( reason=\"To evaluate training progress\", request_block=True, timeout_secs=5 )\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            if loss_value is not None:\n",
    "                print(\"Train Epoch: {} loss {:.4}\".format(i, loss_value))\n",
    "            else:\n",
    "                print(\"Train Epoch: {}\".format(i))\n",
    "\n",
    "        losses.append(loss_value)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        \n",
    "        x =  time.time() - iter_start_time\n",
    "        monitor.QOS =  x\n",
    "        monitor.QOS_list.append(x)\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create the model and pass in our local copy of torch\n",
    "local_model = SyNet(torch) #profiler\n",
    "print(local_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive Remote Data Pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ptr = duet.store[0]\n",
    "target_ptr = duet.store[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnsit = datasets.load_digits()\n",
    "X, y = mnsit.data, mnsit.target\n",
    "\n",
    "_, X_test, _, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=42)\n",
    "\n",
    "X_test = torch.FloatTensor(np.array(X_test))\n",
    "y_test = torch.FloatTensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_optims, remote_models = [], []\n",
    "for m in range(num_of_models):\n",
    "    \n",
    "    remote_models.append(local_model.send(duet))\n",
    "    remote_optims.append(remote_torch.optim.SGD(params=remote_models[m].parameters(), lr=learning_rate))\n",
    "    \n",
    "    \n",
    "print(remote_models)    \n",
    "print(remote_optims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training and track QOS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training on {} - {}\".format(rpi_name,test_name))\n",
    "startTimes, trainingTimes, training_losses = [], [], []      \n",
    "model_number = 1\n",
    "monitor.run_monitor_thread()\n",
    "\n",
    "for r in tqdm(range(num_of_models)):\n",
    "    monitor.task = 'Linear_Regression_Training'\n",
    "    monitor.model_num = model_number\n",
    "    print(\"Round number:\", r+1)\n",
    "    startTimes.append(time.time())\n",
    "    \n",
    "    training_loss  = train(iteration, remote_models[r], remote_torch, remote_optims[r], data_ptr, target_ptr, monitor) #remote_profiler\n",
    "    training_losses.append(training_loss)\n",
    "\n",
    "    trainingTimes.append(time.time() - startTimes[r])\n",
    "    print('Training time:', trainingTimes[-1],'for model', model_number)\n",
    "    model_number += 1\n",
    "    \n",
    "print('Done - Stopping Monitoring thread')\n",
    "time_data = monitor.stop_monitor_thread()\n",
    "monitor.model_num = None\n",
    "monitor.QOS = 0\n",
    "monitor.QOS_list = [0]\n",
    "monitor.task = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data.to_csv('data/{}/QOS_data_{}_{}.csv'.format(rpi_name,rpi_name,test_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rcoin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_model(model):\n",
    "\n",
    "    local_model = model.get(\n",
    "        request_block=True,\n",
    "        reason=\"To run test and inference locally\",\n",
    "        timeout_secs=5,\n",
    "    )\n",
    "\n",
    "    return local_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_models = []\n",
    "for m in range(num_of_models):\n",
    "    local_models.append(get_local_model(remote_models[m]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of models on test data (section of data not used to train model on Worker deivce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 1\n",
    "accuracy = []\n",
    "for model in local_models:\n",
    "    correct = 0\n",
    "    preds = []\n",
    "    \n",
    "    print(\"Test Model\", count)\n",
    "    count += 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i in tqdm(range(len(X_test))):\n",
    "        \n",
    "            sample = X_test[i]\n",
    "            y_hat = model(sample.unsqueeze(0))\n",
    "            pred = y_hat.argmax().item()\n",
    "            \n",
    "            if y_test[i] == pred:\n",
    "                correct += 1\n",
    "                \n",
    "            preds.append(pred)\n",
    "            \n",
    "    accuracy.append(accuracy_score(y_test, preds))\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RCoinP(RCoins,num_of_models):\n",
    "\n",
    "    RCoinPs = []\n",
    "    RCoinPs.append(RCoins[0])\n",
    "    for i in range(1,num_of_models):\n",
    "        if i <= 4:\n",
    "            RCoinPs.append(RCoinPs[i-1] + RCoins[i])\n",
    "        else:\n",
    "            RCoinPs.append(RCoinPs[i-1] + RCoins[i] -  RCoins[i-5])\n",
    "            \n",
    "    return RCoinPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCoins, training_loss_last = [], []\n",
    "for i in range(num_of_models):\n",
    "    training_loss_last.append(training_losses[i][-1])\n",
    "    RCoins.append( (iteration * accuracy[i]) / (training_losses[i][-1] * trainingTimes[i] * learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RCoins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCoinPs = get_RCoinP(RCoins,num_of_models)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {'RCoin':RCoins,'RCoinP':RCoinPs, 'Accuracy':accuracy,'Training Losses': training_loss_last,'Training Times': trainingTimes}\n",
    "\n",
    "out = pd.DataFrame(out_dict)\n",
    "out.to_csv(\"data/{}/RCoin_{}_{}.csv\".format(rpi_name,rpi_name, test_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyMatMull(torch_ref, monitor, n = 512, run_time = 300):\n",
    "    \n",
    "    #FLOPS_SCALE_FACTOR = 100_000_000_000\n",
    "    # this represents the number of floating point computations per matrix mult\n",
    "    ops = (n**3) + ((n-1)*(n**2)) # // n^2*(n-1) additions and n^3 mults\n",
    "    \n",
    "    monitor.task = 'Matrix_Multiplication'\n",
    "    matrix1 = torch.randn(size=(n,n), dtype=torch.float32)\n",
    "    matrix2 = torch.randn(size=(n,n), dtype=torch.float32)\n",
    "\n",
    "    matrix1_pointer = matrix1.send(duet, pointable=True)\n",
    "    matrix1_pointer = matrix2.send(duet, pointable=True)\n",
    "    print('Encryted matrixes sent')\n",
    "    \n",
    "    matrixOut = torch_ref.matmul(matrix1_pointer, matrix1_pointer)\n",
    "\n",
    "    #start = time.time()\n",
    "    #num_iters = 0\n",
    "\n",
    "    # runs the loop for the given amount of time\n",
    "    while (time.time()- run_time < start):\n",
    "        start_matMull = time.time()\n",
    "        matrixOut = torch_ref.matmul(matrix1_pointer, matrix2_pointer)\n",
    "        monitor.QOS = time.time() - start_matMull\n",
    "        monitor.QOS_list.append(time.time() - start_matMull)\n",
    "        \n",
    "        #other QOS measure\n",
    "        #num_iters += 1\n",
    "        #monitor.QOS = (num_iters * ops / ( time.time() - start )) / FLOPS_SCALE_FACTOR\n",
    "        #monitor.QOS_list.append(( num_iters * ops / ( time.time() - start ) ) / FLOPS_SCALE_FACTOR )\n",
    "\n",
    "    del matrix1, matrix2\n",
    "\n",
    "    \n",
    "\n",
    "    # calculates the rate at which the CPU performs floating point computations\n",
    "    #cpu_rate = num_iters * ops / run_time\n",
    "\n",
    "    #return cpu_rate/FLOPS_SCALE_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor.run_monitor_thread()\n",
    "SyMatMull(remote_torch, monitor)\n",
    "monitor.model_num = None\n",
    "monitor.QOS = 0\n",
    "monitor.QOS_list = [0]\n",
    "monitor.task = 'None'\n",
    "#time_data = monitor.stop_monitor_thread()\n",
    "#time_data.to_csv('data/microbench/{}/QOS_data_{}_{}.csv'.format(rpi_name,rpi_name,test_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def SyCholeskyInverse(torch_ref, monitor, n = 512, run_time = 300):\n",
    "    \n",
    "    \n",
    "    monitor.task = 'Cholesky_Inverse'\n",
    "    matrix = torch.randn(size=(n,n), dtype=torch.float32)\n",
    "    matrix = torch.mm(matrix, matrix.t()) + 1e-05 * torch.eye(3)\n",
    "    matrixIn = torch.cholesky(matrix)\n",
    "\n",
    "    matrixIn_pointer = matrixIn.send(duet, pointable=True)\n",
    "    print('Encryted matrixes sent')\n",
    "    \n",
    "    matrixOut = torch_ref.cholesky_inverse(matrixIn_pointer)\n",
    "\n",
    "    # runs the loop for the given amount of time\n",
    "    while (time.time()- run_time < start):\n",
    "        start_cholInv = time.time()\n",
    "        matrixOut = torch_ref.cholesky_inverse(matrixIn_pointer)\n",
    "        monitor.QOS = time.time() - start_cholInv\n",
    "        monitor.QOS_list.append(time.time() - start_cholInv)       \n",
    "\n",
    "    del matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyInverse(torch_ref, monitor, n = 512, run_time = 300):\n",
    "    \n",
    "    # attempt to calculate flops\n",
    "    #FLOPS_SCALE_FACTOR = 100_000_000_000\n",
    "    # this represents the number of floating point computations per matrix mult\n",
    "    #matMulOps = (n**3) + ((n-1)*(n**2)) # // n^2*(n-1) additions and n^3 mults\n",
    "    #LUFactorizationOps = 2 * matMulOps\n",
    "    #lowerTriMatInv = n + n**2 + n**2 # n + n**2 multiplcationas and n**2 additions \n",
    "    #upperTriMatInv = 2*n + n**2\n",
    "    #matInvOps =   LUFactorizationOps  + LUInversion + matMulOps\n",
    "    # the inverse function is composed of an LU factorization (via a mat mul of three matrixes, L us a lower triangular matrix and U in an upper trainagular matrix) using     # the getrf routine and and the inverse of an LU-factored general matrix         \n",
    "    # determined by getri routine. The routines belong to the mkl::lapack namespace\n",
    "    # The getri function computes the inverse of both the triangle matrixes L and U by n^2 and then multiplies the inverses to come up witht the result\n",
    "\n",
    "    monitor.task = 'Inverse'\n",
    "    matrix = torch.randn(size=(n,n), dtype=torch.float32)\n",
    "    \n",
    "    matrix_pointer = matrix.send(duet, pointable=True)\n",
    "    print('Encryted matrixes sent')\n",
    "    \n",
    "    matrixOut = torch_ref.inverse(matrix_pointer)\n",
    "\n",
    "    #start = time.time()\n",
    "    #num_iters = 0\n",
    "\n",
    "    # runs the loop for the given amount of time\n",
    "    while (time.time()- run_time < start):\n",
    "        start_Inv = time.time()\n",
    "        matrixOut = torch_ref.inverse(matrix_pointer)\n",
    "        monitor.QOS = time.time() - start_Inv\n",
    "        monitor.QOS_list.append(time.time() - start_Inv) \n",
    "                \n",
    "        #num_iters += 1\n",
    "        #monitor.QOS = (num_iters * ops / ( time.time() - start )) / FLOPS_SCALE_FACTOR\n",
    "        #monitor.QOS_list.append(( num_iters * ops / ( time.time() - start ) ) / FLOPS_SCALE_FACTOR )\n",
    "\n",
    "    del matrix\n",
    "\n",
    "    # calculates the rate at which the CPU performs floating point computations\n",
    "    #cpu_rate = num_iters * ops / run_time\n",
    "\n",
    "    #return cpu_rate/FLOPS_SCALE_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor.run_monitor_thread()\n",
    "cpu_rate = SyCholeskyInverse(remote_torch, monitor)\n",
    "print(cpu_rate)\n",
    "monitor.model_num = None\n",
    "monitor.QOS = 0\n",
    "monitor.QOS_list = [0]\n",
    "monitor.task = 'None'\n",
    "#time_data = monitor.stop_monitor_thread()\n",
    "#time_data.to_csv('data/microbench/{}/QOS_data_{}_{}.csv'.format(rpi_name,rpi_name,test_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SyArrAccess(duet, monitor, arrLength = 100000, arrElementMax = 999999):\n",
    "    \n",
    "    monitor.task = 'Array Access'\n",
    "    \n",
    "    seed = int(time.time())\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    arr = np.empty(shape=(arrLength,2))\n",
    "    indexArr = np.arange(arrLength)\n",
    "    np.random.shuffle(indexArr)\n",
    "    \n",
    "    for i in range(arrLength):\n",
    "        arr[i,0] = np.random.randint(arrElementMax)\n",
    "        arr[i,1] = indexArr[i]\n",
    "    \n",
    "    arr = torch.FloatTensor(arr)\n",
    "    \n",
    "    arr = arr.tag(\"Send Tensor\")\n",
    "    arr = arr.describe(\"This 2D tensor contains randomized elements and access indexes for memory test with length \" + str(arrLength))\n",
    "\n",
    "    arr_ptr = arr.send(duet, pointable=True)\n",
    "    print('Tensor sent')\n",
    "    \n",
    "    searchFlag = True\n",
    "    print('Waiting to receive result')\n",
    "                   \n",
    "    while searchFlag == True:\n",
    "        for ptr in duet.store:\n",
    "            if ptr.tags[0] == 'Return Tensor':\n",
    "                ptr.request(reason = \"Why I ought'a ...\")\n",
    "                time.sleep(5)\n",
    "                squencedArrInfo = ptr.get()\n",
    "                searchFlag = False\n",
    "                print('Result received')  \n",
    "                   \n",
    "                return arr, arr_ptr, squencedArrInfo\n",
    "            \n",
    "def seqArrayCheck(arr, squencedArrInfo):\n",
    "    \n",
    "    squencedArrInfoNumpy = squencedArrInfo.numpy()\n",
    "    arrNumpy = arr[:,0].numpy()\n",
    "    indexArrNumpy = arr[:,1].numpy()\n",
    "\n",
    "    index = 0\n",
    "    squencedArr = squencedArrInfoNumpy[:,2]\n",
    "    \n",
    "    for i in indexArrNumpy:\n",
    "        if arrNumpy[int(i)] != squencedArr[index]:\n",
    "            print('Mismatch Error')\n",
    "            return False\n",
    "        index += 1\n",
    "    print(\"Arrays Match\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp_list = []\n",
    "\n",
    "monitor.run_monitor_thread()\n",
    "arr, arr_ptr, squencedArrInfo = SyArrAccess(duet, monitor, 100000, 999999)\n",
    "if seqArrayCheck(arr, squencedArrInfo) == True:\n",
    "    \n",
    "    squencedArrInfoNumpy = squencedArrInfo.numpy()\n",
    "    \n",
    "    for timeStamp in squencedArrInfoNumpy[:,0]:\n",
    "    \n",
    "        timeObj = time.localtime(timeStamp)\n",
    "        # creates time stamp Day-Month-Year Hour:Minute:Second\n",
    "        time_stamp_list.append(str(timeObj.tm_mday) + '-' + str(timeObj.tm_mon) + '-' + str(timeObj.tm_year) + ' ' + str(timeObj.tm_hour) + ':' + str(timeObj.tm_min) + ':' + str(timeObj.tm_sec))\n",
    "     \n",
    "    squencedArrInfoDF = pd.DataFrame.from_dict({'time_stamp':time_stamp_list, 'time':squencedArrInfoNumpy[:,0],'memory_access_time':squencedArrInfoNumpy[:,1]})\n",
    "    squencedArrInfoDF = squencedArrInfoDF.set_index('time_stamp')\n",
    "    \n",
    "    monitor.model_num = None\n",
    "    monitor.QOS = 0\n",
    "    monitor.QOS_list = [0]\n",
    "    monitor.task = 'None'\n",
    "    time_data = monitor.stop_monitor_thread()\n",
    "    time_data.to_csv('data/microbench/{}/QOS_data_{}_{}.csv'.format(rpi_name,rpi_name,test_name))\n",
    "    squencedArrInfoDF.to_csv('data/microbench/{}/ArrInfo_data_{}_{}.csv'.format(rpi_name,rpi_name,test_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
